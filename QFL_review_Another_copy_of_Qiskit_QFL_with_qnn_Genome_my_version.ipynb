{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/QFL_Experiments/blob/main/QFL_review_Another_copy_of_Qiskit_QFL_with_qnn_Genome_my_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdPhLlT9q3Np"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Us3DV6Sfq6Mw"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "word_size = 40\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample int the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:70000]\n",
        "np_test_data = np_data_set[-5000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:70000]\n",
        "np_test_data = np_data_set[-5000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n",
        "print(f\"Length of Test data: {len(test_sequences)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r4S1g9FC5nH",
        "outputId": "6c049a80-e3ac-4a94-b40b-89dab4b1514c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample int the data_set variable: \n",
            "('TACCAACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTCCATGCCCACTCCTGAACCAATTATAATGTTAGGAGGATGGGAAACTGACTAACCCCCCTGTGTTTTGTGTCTATCTCAATTAAATAGTATTGTCTCTTTTCAGAAGATGGAGTTGGGAGAAAACACTGGGCAGCCTCTCAGCGCTCAACTCCCCAAACTG', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "TACCAACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTC 1\n",
            "ACCAACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTCC 2\n",
            "CCAACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTCCA 3\n",
            "CAACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTCCAT 4\n",
            "AACCTAGGGAGCCATCTAATTGGTGTTGTCTGAGTCCATG 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of Test data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcRZf8-bLOQH",
        "outputId": "d7a35fa4-10f5-4346-c298-c39ae82d651a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of Test data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the structure of np_test_data\n",
        "for i, data_point in enumerate(np_test_data[:5]):  # Print the first 5 test data points\n",
        "    print(f\"Test data point {i}: {data_point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTLOJOQeLRg7",
        "outputId": "cb0f4c08-0495-4adb-d6cc-dd0c117d626b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data point 0: {'sequence': array([0.73816034, 0.73816034, 0.73816034, 0.73816034, 0.73816034]), 'label': 1}\n",
            "Test data point 1: {'sequence': array([0.54409911, 0.54409911, 0.54409911, 0.54409911, 0.54409911]), 'label': 1}\n",
            "Test data point 2: {'sequence': array([0.04371044, 0.04371044, 0.04371044, 0.04371044, 0.04371044]), 'label': 0}\n",
            "Test data point 3: {'sequence': array([0.41804649, 0.41804649, 0.41804649, 0.41804649, 0.41804649]), 'label': 0}\n",
            "Test data point 4: {'sequence': array([0.46790039, 0.46790039, 0.46790039, 0.46790039, 0.46790039]), 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vM9FXroZu1bK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "num_clients = 5\n",
        "num_epochs = 20\n",
        "max_train_iterations = 50\n",
        "samples_per_epoch=100\n",
        "backend = Aer.get_backend('aer_simulator')\n",
        "\n",
        "class Client:\n",
        "   def __init__(self, train_data):  # Add test_data to __init__\n",
        "        self.client_train_data = train_data\n",
        "        #self.test_data = test_data  # Store test_data as an attribute\n",
        "        self.models = []\n",
        "        self.train_scores = []\n",
        "        self.test_scores = []\n",
        "        self.primary_model = None\n",
        "'''\n",
        "def split_dataset(num_clients, num_epochs, samples_per_epoch):\n",
        "  clients = []\n",
        "  for i in range(num_clients):\n",
        "    client_data = []\n",
        "    for j in range(num_epochs):\n",
        "      start_idx = (i*num_epochs*samples_per_epoch)+(j*samples_per_epoch)\n",
        "      end_idx = (i*num_epochs*samples_per_epoch)+((j+1)*samples_per_epoch)\n",
        "      client_data.append(np_train_data[start_idx:end_idx])\n",
        "    # Pass test_data when creating Client instances\n",
        "    clients.append(Client(client_data, np_test_data))\n",
        "  return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "'''\n",
        "def split_dataset(num_clients, num_epochs, samples_per_epoch):\n",
        "    clients = []\n",
        "    # Split test data across clients\n",
        "    #test_samples_per_client = len(test_sample_sequences) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_train_data = []\n",
        "        for j in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\n",
        "            client_train_data.append(np_train_data[start_idx:end_idx])\n",
        "            #print(f\"Client {i+1} training data size: {len(np_train_data[start_idx:end_idx])}\")\n",
        "        # Assign a subset of the test data to each client\n",
        "        #test_start_idx = i * test_samples_per_client\n",
        "        #test_end_idx = (i + 1) * test_samples_per_client\n",
        "        #client_test_data = test_sample_sequences[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create Client instance with both train and test data\n",
        "        clients.append(Client(client_train_data))\n",
        "\n",
        "    return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "\n",
        "itr = 0\n",
        "def training_callback(weights, obj_func_eval):\n",
        "        global itr\n",
        "        itr += 1\n",
        "        print(f\"{itr}\", end=' | ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_AV8hy8zY_R"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vMGbsnFLzZhB"
      },
      "outputs": [],
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Callback function to visualize training progress\n",
        "objective_func_vals = []\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SE9YYRwPJDau"
      },
      "outputs": [],
      "source": [
        "# Function to initialize a new QNN model (same architecture as clients' models)\n",
        "def initialize_model(num_features):\n",
        "    # Create the same quantum neural network (QNN) architecture as clients\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Combine the feature map and ansatz into a single quantum circuit\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Input parameters (for encoding)\n",
        "    weight_params = ansatz.parameters      # Trainable parameters (for optimization)\n",
        "\n",
        "    # Define the QNN model using a sampler\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Binary classification\n",
        "        input_params=input_params,\n",
        "        weight_params=weight_params\n",
        "    )\n",
        "\n",
        "    # Create a classifier using the neural network\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50)  # Use SPSA optimizer\n",
        "    )\n",
        "\n",
        "    return qnn_classifier\n",
        "\n",
        "# Function to create a model with averaged weights\n",
        "def create_model_with_weights(average_weights, num_features):\n",
        "    # Initialize a new QNN model with the same architecture\n",
        "    model = initialize_model(num_features)\n",
        "    # Assign the averaged weights to the model's trainable parameters (ansatz weights)\n",
        "    weight_params = model.neural_network.weight_params  # Get the trainable parameters\n",
        "\n",
        "    # Check if the lengths match, and truncate if necessary\n",
        "    num_weights = min(len(average_weights), len(weight_params))\n",
        "\n",
        "    # Create a dictionary mapping parameters to averaged weights\n",
        "    param_dict = {param: average_weights[i] for i, param in enumerate(weight_params[:num_weights])}\n",
        "\n",
        "\n",
        "    # Assign the averaged weights to the circuit parameters\n",
        "    model.neural_network.circuit.assign_parameters(param_dict)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j-HD-sL2zgxh"
      },
      "outputs": [],
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Callback function to visualize training progress\n",
        "objective_func_vals = []\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()\n",
        "\n",
        "# Function to create the QNN model\n",
        "def create_qnn_model(num_features):\n",
        "    # num_features = data_train[0][\"sequence\"].shape[0]  # Remove this line as data_train is not defined\n",
        "    # Define the quantum feature map and ansatz\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)  # Use num_features passed as argument\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Construct the quantum neural network using a sampler\n",
        "    qc = feature_map.compose(ansatz)  # Build the QNN circuit\n",
        "    print(f\"Number of features (input dimension): {num_features}\")\n",
        "    print(f\"Number of circuit parameters: {qc.num_parameters}\")\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Parameters for the feature map (inputs)\n",
        "    weight_params = ansatz.parameters      # Parameters for the ansatz (weights)\n",
        "    #print(f\"Input Parameters: {input_params}\")\n",
        "    #print(f\"Weight Parameters: {weight_params}\")\n",
        "\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Output dimension for binary classification\n",
        "        input_params=input_params,       # Pass input parameters\n",
        "        weight_params=weight_params     # Pass weight parameters\n",
        "    )\n",
        "\n",
        "    # Define a classifier using the QNN\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50),  # Example with SPSA optimizer\n",
        "        #callback=callback_graph\n",
        "    )\n",
        "\n",
        "    return qnn_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IkECBNFLazNA"
      },
      "outputs": [],
      "source": [
        "def getAccuracy(weights, num_features, test_sequences, test_labels):\n",
        "    # Rebuild the QNN model with the given weights\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Replace bind_parameters with assign_parameters\n",
        "    # Create a parameter dictionary for assignment\n",
        "    param_dict = {param: weight for param, weight in zip(ansatz.parameters, weights)}\n",
        "    ansatz = ansatz.assign_parameters(param_dict)\n",
        "\n",
        "    # Rebuild the QNN using the updated ansatz\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Define the parity function for binary classification\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2\n",
        "\n",
        "    # Build the SamplerQNN with the updated circuit\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Binary classification\n",
        "        input_params=feature_map.parameters,  # Input parameters (from the feature map)\n",
        "        weight_params=ansatz.parameters  # Weight parameters (from the ansatz)\n",
        "    )\n",
        "\n",
        "    # Build the NeuralNetworkClassifier with the QNN\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=COBYLA(maxiter=0)  # No need for further optimization\n",
        "    )\n",
        "\n",
        "    # Train the classifier on a subset of test data (or use full test data if preferred)\n",
        "    qnn_classifier.fit(test_sequences, test_labels)\n",
        "\n",
        "    # Return the accuracy on a larger test set\n",
        "    return qnn_classifier.score(test_sequences, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CSV_PATH = '/content/drive/MyDrive/QFL_folder/federated_qnn_metrics_genome.csv'  # change if you like\n",
        "os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def init_metrics_csv(csv_path: str, num_clients: int):\n",
        "    \"\"\"Create/overwrite CSV with a header.\"\"\"\n",
        "    header = ['Epoch', 'GlobalAccuracy']\n",
        "    for i in range(num_clients):\n",
        "        header += [f'Client{i}_TrainAcc', f'Client{i}_TestAcc']\n",
        "    with open(csv_path, 'w', newline='') as f:\n",
        "        csv.writer(f).writerow(header)\n",
        "\n",
        "def append_metrics_row(csv_path: str, epoch: int, global_acc: float,\n",
        "                       train_accs: list[float], test_accs: list[float]):\n",
        "    \"\"\"Append one epochâ€™s metrics.\"\"\"\n",
        "    row = [epoch, global_acc] + [\n",
        "        x for pair in zip(train_accs, test_accs) for x in pair\n",
        "    ]\n",
        "    with open(csv_path, 'a', newline='') as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "def compute_global_accuracy(model, clients: list[dict]) -> float:\n",
        "    \"\"\"Evaluate the current global model on the union of all client test sets.\"\"\"\n",
        "    X = np.concatenate([c[\"test_data\"][\"sequence\"] for c in clients], axis=0)\n",
        "    y = np.concatenate([c[\"test_data\"][\"label\"]   for c in clients],   axis=0)\n",
        "    return float(model.score(X, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTktmHkiuWhn",
        "outputId": "9d407d2c-e612-417e-b236-7c3d87d82411"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ucS5zEozmN5",
        "outputId": "95116d4c-5b6b-4e47-d8c1-4b87da445a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Training Client 0\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 133.5044767856598 seconds.\n",
            "Client 0 Train Score: 0.67\n",
            "Client 0 Test Score: 0.6774\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 135.0286684036255 seconds.\n",
            "Client 1 Train Score: 0.92\n",
            "Client 1 Test Score: 0.9212\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 136.72768902778625 seconds.\n",
            "Client 2 Train Score: 0.79\n",
            "Client 2 Test Score: 0.7858\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 135.02850484848022 seconds.\n",
            "Client 3 Train Score: 0.73\n",
            "Client 3 Test Score: 0.729\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 159.02631664276123 seconds.\n",
            "Client 4 Train Score: 0.73\n",
            "Client 4 Test Score: 0.6956\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 0] global_acc=0.5200 | train=[0.67, 0.92, 0.79, 0.73, 0.73] | test=[0.6774, 0.9212, 0.7858, 0.729, 0.6956]\n",
            "Epoch: 1\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 148.65637063980103 seconds.\n",
            "Client 0 Train Score: 0.81\n",
            "Client 0 Test Score: 0.8574\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 142.15093660354614 seconds.\n",
            "Client 1 Train Score: 0.77\n",
            "Client 1 Test Score: 0.711\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 137.79507899284363 seconds.\n",
            "Client 2 Train Score: 0.7\n",
            "Client 2 Test Score: 0.728\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 133.69629979133606 seconds.\n",
            "Client 3 Train Score: 0.72\n",
            "Client 3 Test Score: 0.6782\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 137.22384524345398 seconds.\n",
            "Client 4 Train Score: 0.86\n",
            "Client 4 Test Score: 0.8476\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 1] global_acc=0.3140 | train=[0.81, 0.77, 0.7, 0.72, 0.86] | test=[0.8574, 0.711, 0.728, 0.6782, 0.8476]\n",
            "Epoch: 2\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 141.68346691131592 seconds.\n",
            "Client 0 Train Score: 0.77\n",
            "Client 0 Test Score: 0.7764\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 139.76552271842957 seconds.\n",
            "Client 1 Train Score: 0.76\n",
            "Client 1 Test Score: 0.7216\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 137.3454396724701 seconds.\n",
            "Client 2 Train Score: 0.7\n",
            "Client 2 Test Score: 0.707\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 135.20302844047546 seconds.\n",
            "Client 3 Train Score: 0.8\n",
            "Client 3 Test Score: 0.83\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 140.31252026557922 seconds.\n",
            "Client 4 Train Score: 0.87\n",
            "Client 4 Test Score: 0.824\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 2] global_acc=0.4260 | train=[0.77, 0.76, 0.7, 0.8, 0.87] | test=[0.7764, 0.7216, 0.707, 0.83, 0.824]\n",
            "Epoch: 3\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 133.21645379066467 seconds.\n",
            "Client 0 Train Score: 0.92\n",
            "Client 0 Test Score: 0.8698\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 134.20300960540771 seconds.\n",
            "Client 1 Train Score: 0.91\n",
            "Client 1 Test Score: 0.8684\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 131.2541172504425 seconds.\n",
            "Client 2 Train Score: 0.8\n",
            "Client 2 Test Score: 0.765\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 135.09286952018738 seconds.\n",
            "Client 3 Train Score: 0.81\n",
            "Client 3 Test Score: 0.7602\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 146.2801399230957 seconds.\n",
            "Client 4 Train Score: 0.85\n",
            "Client 4 Test Score: 0.7742\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 3] global_acc=0.7320 | train=[0.92, 0.91, 0.8, 0.81, 0.85] | test=[0.8698, 0.8684, 0.765, 0.7602, 0.7742]\n",
            "Epoch: 4\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 134.8735547065735 seconds.\n",
            "Client 0 Train Score: 0.9\n",
            "Client 0 Test Score: 0.8878\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 135.41537427902222 seconds.\n",
            "Client 1 Train Score: 0.62\n",
            "Client 1 Test Score: 0.569\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 134.7882959842682 seconds.\n",
            "Client 2 Train Score: 0.86\n",
            "Client 2 Test Score: 0.7864\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 133.97694396972656 seconds.\n",
            "Client 3 Train Score: 0.75\n",
            "Client 3 Test Score: 0.7402\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 133.91529726982117 seconds.\n",
            "Client 4 Train Score: 0.8\n",
            "Client 4 Test Score: 0.8284\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 4] global_acc=0.4860 | train=[0.9, 0.62, 0.86, 0.75, 0.8] | test=[0.8878, 0.569, 0.7864, 0.7402, 0.8284]\n",
            "Epoch: 5\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 152.12775540351868 seconds.\n",
            "Client 0 Train Score: 0.8\n",
            "Client 0 Test Score: 0.827\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 135.10853838920593 seconds.\n",
            "Client 1 Train Score: 0.79\n",
            "Client 1 Test Score: 0.8048\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 134.6980493068695 seconds.\n",
            "Client 2 Train Score: 0.73\n",
            "Client 2 Test Score: 0.6548\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 132.88614463806152 seconds.\n",
            "Client 3 Train Score: 0.9\n",
            "Client 3 Test Score: 0.8144\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 134.08296871185303 seconds.\n",
            "Client 4 Train Score: 0.7\n",
            "Client 4 Test Score: 0.643\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 5] global_acc=0.6200 | train=[0.8, 0.79, 0.73, 0.9, 0.7] | test=[0.827, 0.8048, 0.6548, 0.8144, 0.643]\n",
            "Epoch: 6\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 133.00669384002686 seconds.\n",
            "Client 0 Train Score: 0.82\n",
            "Client 0 Test Score: 0.7918\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 132.5889081954956 seconds.\n",
            "Client 1 Train Score: 0.92\n",
            "Client 1 Test Score: 0.863\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 136.20557832717896 seconds.\n",
            "Client 2 Train Score: 0.81\n",
            "Client 2 Test Score: 0.7754\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 136.80438995361328 seconds.\n",
            "Client 3 Train Score: 0.85\n",
            "Client 3 Test Score: 0.8832\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 136.54163193702698 seconds.\n",
            "Client 4 Train Score: 0.87\n",
            "Client 4 Test Score: 0.8558\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 6] global_acc=0.5440 | train=[0.82, 0.92, 0.81, 0.85, 0.87] | test=[0.7918, 0.863, 0.7754, 0.8832, 0.8558]\n",
            "Epoch: 7\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 143.87795543670654 seconds.\n",
            "Client 0 Train Score: 0.76\n",
            "Client 0 Test Score: 0.7532\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 139.48188018798828 seconds.\n",
            "Client 1 Train Score: 0.67\n",
            "Client 1 Test Score: 0.6604\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 139.25038194656372 seconds.\n",
            "Client 2 Train Score: 0.92\n",
            "Client 2 Test Score: 0.8624\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 138.69591903686523 seconds.\n",
            "Client 3 Train Score: 0.6\n",
            "Client 3 Test Score: 0.529\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 138.5442669391632 seconds.\n",
            "Client 4 Train Score: 0.79\n",
            "Client 4 Test Score: 0.8114\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 7] global_acc=0.6060 | train=[0.76, 0.67, 0.92, 0.6, 0.79] | test=[0.7532, 0.6604, 0.8624, 0.529, 0.8114]\n",
            "Epoch: 8\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 138.6731173992157 seconds.\n",
            "Client 0 Train Score: 0.79\n",
            "Client 0 Test Score: 0.7858\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 140.37837147712708 seconds.\n",
            "Client 1 Train Score: 0.92\n",
            "Client 1 Test Score: 0.8294\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 135.1073122024536 seconds.\n",
            "Client 2 Train Score: 0.68\n",
            "Client 2 Test Score: 0.677\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 151.58085322380066 seconds.\n",
            "Client 3 Train Score: 0.89\n",
            "Client 3 Test Score: 0.8584\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 145.72185850143433 seconds.\n",
            "Client 4 Train Score: 0.82\n",
            "Client 4 Test Score: 0.7756\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 8] global_acc=0.6140 | train=[0.79, 0.92, 0.68, 0.89, 0.82] | test=[0.7858, 0.8294, 0.677, 0.8584, 0.7756]\n",
            "Epoch: 9\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 143.9993453025818 seconds.\n",
            "Client 0 Train Score: 0.81\n",
            "Client 0 Test Score: 0.8038\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 142.877760887146 seconds.\n",
            "Client 1 Train Score: 0.62\n",
            "Client 1 Test Score: 0.645\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 141.3838770389557 seconds.\n",
            "Client 2 Train Score: 0.84\n",
            "Client 2 Test Score: 0.8174\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 139.29719710350037 seconds.\n",
            "Client 3 Train Score: 0.88\n",
            "Client 3 Test Score: 0.8412\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 145.6847472190857 seconds.\n",
            "Client 4 Train Score: 0.84\n",
            "Client 4 Test Score: 0.8546\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 9] global_acc=0.6520 | train=[0.81, 0.62, 0.84, 0.88, 0.84] | test=[0.8038, 0.645, 0.8174, 0.8412, 0.8546]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Lists to store accuracies over epochs\n",
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "clients_train_accuracies = []  # List to store train accuracies per epoch per client\n",
        "clients_test_accuracies = []   # List to store test accuracies per epoch per client\n",
        "\n",
        "# Function to train the QNN model for one client\n",
        "def train_qnn_model(client_data, client_test_data, model=None):\n",
        "    if model is None:\n",
        "        # Create a new QNN model if one doesn't exist\n",
        "        num_features = client_data[0][\"sequence\"].shape[0]\n",
        "        model = create_qnn_model(num_features)  # Pass num_features\n",
        "\n",
        "    # Extract sequences and labels for training\n",
        "    train_sequences = [data_point[\"sequence\"] for data_point in client_data]\n",
        "    train_labels = [data_point[\"label\"] for data_point in client_data]\n",
        "\n",
        "    # Extract sequences and labels for testing\n",
        "    test_sequences = [data_point[\"sequence\"] for data_point in client_test_data]\n",
        "    test_labels = [data_point[\"label\"] for data_point in client_test_data]\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    train_sequences = np.array(train_sequences)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_sequences = np.array(test_sequences)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    print(\"Training started...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the QNN model\n",
        "    model.fit(train_sequences, train_labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training completed in {elapsed_time} seconds.\")\n",
        "\n",
        "    # Evaluate the model on training and test data\n",
        "    train_score_q = model.score(train_sequences, train_labels)\n",
        "    test_score_q = model.score(test_sequences, test_labels)\n",
        "\n",
        "    return model, train_score_q, test_score_q, elapsed_time\n",
        "\n",
        "# Function to manually average the numerical values of the parameters across clients\n",
        "def manual_average_weights(epoch_weights):\n",
        "    # Initialize a list to store the summed weights (initialize with zeros)\n",
        "    num_weights = len(epoch_weights[0])  # Number of weights in the model\n",
        "    num_clients = len(epoch_weights)  # Number of clients\n",
        "\n",
        "    # Initialize sum of weights to zero (assuming NumPy array or list of weights)\n",
        "    summed_weights = np.zeros(num_weights)\n",
        "\n",
        "    # Sum the weights from all clients\n",
        "    for client_weights in epoch_weights:\n",
        "        summed_weights += np.array(client_weights)\n",
        "\n",
        "    # Compute the average by dividing the summed weights by the number of clients\n",
        "    average_weights = summed_weights / num_clients\n",
        "\n",
        "    return average_weights\n",
        "\n",
        "# Function to save accuracies to CSV\n",
        "def save_accuracies_to_csv(global_accuracies, clients_train_accuracies, clients_test_accuracies, filename='accuracies.csv'):\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        header = ['Epoch', 'Global Accuracy']\n",
        "        for i in range(len(clients_train_accuracies[0])):  # Assuming all clients have the same number of records\n",
        "            header.append(f'Client {i} Train Accuracy')\n",
        "            header.append(f'Client {i} Test Accuracy')\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write the accuracy data for each epoch\n",
        "        for epoch in range(len(global_accuracies)):\n",
        "            row = [epoch, global_accuracies[epoch]]  # Start with epoch and global accuracy\n",
        "            for client_index in range(len(clients_train_accuracies[epoch])):\n",
        "                row.append(clients_train_accuracies[epoch][client_index])  # Add train accuracy for client\n",
        "                row.append(clients_test_accuracies[epoch][client_index])   # Add test accuracy for client\n",
        "            writer.writerow(row)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _logits_to_labels(y_raw: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Robust conversion from network outputs to class labels.\"\"\"\n",
        "    y_raw = np.asarray(y_raw)\n",
        "    if y_raw.ndim == 1:\n",
        "        # Binary, single logit (e.g., expectation). Threshold at 0.\n",
        "        return (y_raw >= 0).astype(int)\n",
        "    elif y_raw.ndim == 2:\n",
        "        if y_raw.shape[1] == 1:\n",
        "            return (y_raw[:, 0] >= 0).astype(int)\n",
        "        # Multi-class or 2-class with 2 outputs\n",
        "        return np.argmax(y_raw, axis=1)\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected network output shape: {}\".format(y_raw.shape))\n",
        "\n",
        "\n",
        "def compute_global_accuracy_from_weights(prototype_model, avg_weights: np.ndarray, clients: list) -> float:\n",
        "    \"\"\"\n",
        "    Use a *fitted* prototype_model to access its underlying QNN and\n",
        "    forward the averaged parameter vector 'avg_weights' over the\n",
        "    concatenated global test set, returning accuracy.\n",
        "    \"\"\"\n",
        "    # 1) Build the global test pool\n",
        "    Xg = np.concatenate([np.array(item[\"sequence\"]).reshape(1, -1) for c in clients for item in c.client_train_data[0]], axis=0)\n",
        "    yg = np.concatenate([np.array(item[\"label\"]).reshape(1,) for c in clients for item in c.client_train_data[0]], axis=0)\n",
        "\n",
        "\n",
        "    # 2) Extract the underlying QNN (works for NeuralNetworkClassifier built on {Sampler,Estimator}QNN)\n",
        "    qnn = getattr(prototype_model, \"neural_network\", None)\n",
        "    if qnn is None:\n",
        "        # Some versions use a protected attribute\n",
        "        qnn = getattr(prototype_model, \"_neural_network\", None)\n",
        "    if qnn is None:\n",
        "        raise RuntimeError(\"Cannot access underlying QNN from the classifier.\")\n",
        "\n",
        "    # 3) Forward pass with the *averaged* parameter vector (no fit needed)\n",
        "    y_raw = qnn.forward(Xg, np.asarray(avg_weights))\n",
        "\n",
        "    # 4) Convert to labels and compute accuracy\n",
        "    y_pred = _logits_to_labels(y_raw)\n",
        "    return float(np.mean(y_pred == yg))\n",
        "\n",
        "\n",
        "# Federated learning loop\n",
        "num_features = 5\n",
        "num_epochs = 10\n",
        "global_model_weights = {}\n",
        "\n",
        "num_clients = len(clients)\n",
        "init_metrics_csv(CSV_PATH, num_clients)\n",
        "global_model_accuracy = []\n",
        "# Initialize 'primary_model' for each client\n",
        "for client in clients:  # Assuming 'clients' is your list of client dictionaries\n",
        "    client.primary_model = None  # Initialize 'primary_model' to None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "\n",
        "    epoch_train_accuracies = []  # Store train accuracies for this epoch\n",
        "    epoch_test_accuracies = []   # Store test accuracies for this epoch\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "        # Use dictionary key access instead of dot notation\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.client_train_data[epoch], np_test_data) # Use client.client_train_data and np_test_data\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.client_train_data[epoch], np_test_data, model=client.primary_model) # Use client.client_train_data and np_test_data\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"\\n\\n\")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        # Append client accuracies for this epoch\n",
        "        epoch_train_accuracies.append(train_score_q)\n",
        "        epoch_test_accuracies.append(test_score_q)\n",
        "\n",
        "        # Collect model weights (assuming model has a \"weights\" attribute that can be averaged)\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "   # Manually compute the average weights\n",
        "    average_weights = manual_average_weights(epoch_weights)\n",
        "\n",
        "    # Update the global model weights\n",
        "    print(\"Global model updated\")\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    # --- remove these lines ---\n",
        "# new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch], num_features)\n",
        "# for index, client in enumerate(clients):\n",
        "#     client[\"primary_model\"] = new_model_with_global_weights\n",
        "# global_acc = compute_global_accuracy(new_model_with_global_weights, clients)\n",
        "# --------------------------------\n",
        "\n",
        "    # --- insert this instead ---\n",
        "    avg_w = global_model_weights[epoch]\n",
        "    # Use any client model that was trained this epoch as a *fitted prototype*:\n",
        "    prototype = clients[0].primary_model # Use dot notation\n",
        "    global_acc = compute_global_accuracy_from_weights(prototype, avg_w, clients)\n",
        "    global_model_accuracy.append(global_acc)\n",
        "\n",
        "    # set starting point for the NEXT epochâ€™s training\n",
        "    for c in clients:\n",
        "        c.next_init = avg_w.copy() # Use dot notation\n",
        "        c.primary_model.initial_point = np.asarray(avg_w) # Use dot notation\n",
        "\n",
        "\n",
        "    # # Calculate global accuracy using the test data\n",
        "    # test_sequences = clients[0][\"test_data\"][\"sequence\"]  # Access test_sequences\n",
        "    # test_labels = clients[0][\"test_data\"][\"label\"]  # Access test_labels\n",
        "    # global_accuracy = getAccuracy(global_model_weights[epoch], num_features, test_sequences, test_labels)\n",
        "    # global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    # Save the clients' train/test accuracies for this epoch\n",
        "    clients_train_accuracies.append(epoch_train_accuracies)\n",
        "    clients_test_accuracies.append(epoch_test_accuracies)\n",
        "\n",
        "    # compute global accuracy on the combined test set\n",
        "    # global_acc = compute_global_accuracy(new_model_with_global_weights, clients) # This line was removed in the original cell\n",
        "    # global_model_accuracy.append(global_acc) # This line was removed in the original cell\n",
        "\n",
        "    # APPEND one row to Drive for this epoch\n",
        "    append_metrics_row(\n",
        "        CSV_PATH,\n",
        "        epoch,\n",
        "        global_acc,\n",
        "        epoch_train_accuracies,\n",
        "        epoch_test_accuracies\n",
        "    )\n",
        "\n",
        "    # print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    print(f\"[Epoch {epoch}] global_acc={global_acc:.4f} \"\n",
        "          f\"| train={epoch_train_accuracies} | test={epoch_test_accuracies}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fxtq4-9VQsF"
      },
      "source": [
        "Visualizing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9T-8JBzwMo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "filename = 'accuracies.csv'\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Extract the relevant columns for plotting\n",
        "epochs = data['Epoch']\n",
        "global_accuracy = data['Global Accuracy']\n",
        "client_train_accuracies = data.filter(like='Train Accuracy').values\n",
        "client_test_accuracies = data.filter(like='Test Accuracy').values\n",
        "\n",
        "# Plot Global Accuracy over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, global_accuracy, label='Global Accuracy', color='blue', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.title('Global Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Train Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_train_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_train_accuracies[:, i], label=f'Client {i} Train Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('Train Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_test_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_test_accuracies[:, i], label=f'Client {i} Test Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_q7UqBTcju"
      },
      "source": [
        "new ways to average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd3Im7PfTkl9"
      },
      "outputs": [],
      "source": [
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # First time training: no existing model\n",
        "            train_score_q, test_score_q, model = train(data=client.data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            # Continue training with the existing model\n",
        "            train_score_q, test_score_q, model = train(data=client.data[epoch], model=client.primary_model)\n",
        "\n",
        "        # Save model and scores\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        # Extract and collect model weights\n",
        "        print(f\"Train Score: {train_score_q}\")\n",
        "        print(f\"Test Score: {test_score_q}\")\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "        # Assuming model.weights returns a NumPy array or list of weights\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "    # Average the weights across all clients\n",
        "    average_weights = sum(epoch_weights) / len(epoch_weights)\n",
        "\n",
        "    # Create a new model with the averaged global weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "    new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch])\n",
        "\n",
        "    # Update each client's primary model with the global averaged weights\n",
        "    for index, client in enumerate(clients):\n",
        "        client.primary_model = new_model_with_global_weights\n",
        "\n",
        "    # Optionally calculate global accuracy (if applicable in your case)\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])  # Assuming getAccuracy() works with global weights\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skaTQsAsTbbr"
      },
      "outputs": [],
      "source": [
        "# Function to extract numerical values of parameters\n",
        "def extract_param_values(model):\n",
        "    param_values = []\n",
        "    # Loop through each parameter in the circuit and get its bound value\n",
        "    for param in model.neural_network.circuit.parameters:\n",
        "        # Extract the numerical value (assuming they are already bound with values)\n",
        "        bound_value = model.neural_network.circuit._parameters[param]\n",
        "        param_values.append(bound_value)\n",
        "    return np.array(param_values)\n",
        "\n",
        "# Function to set numerical values of parameters back into the circuit\n",
        "def set_param_values(model, param_values):\n",
        "    # Assign the averaged parameter values back to the circuit\n",
        "    parameter_dict = {param: value for param, value in zip(model.neural_network.circuit.parameters, param_values)}\n",
        "    model.neural_network.circuit.assign_parameters(parameter_dict)\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch], model=client.primary_model)\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"  \")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        # Collect model weights (extract numerical parameter values)\n",
        "        param_values = extract_param_values(client.primary_model)\n",
        "        epoch_weights.append(param_values)\n",
        "\n",
        "    # Average the numerical values of the parameters across clients\n",
        "    average_weights = np.mean(epoch_weights, axis=0)\n",
        "\n",
        "    # Manually update each client's model parameters with the averaged weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    for client in clients:\n",
        "        # Manually set the global averaged weights to the model's parameters\n",
        "        set_param_values(client.primary_model, global_model_weights[epoch])\n",
        "\n",
        "    # Calculate global accuracy\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "\n",
        "    # Print global accuracy for the epoch\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8swGngN3RP"
      },
      "source": [
        "33333333333333333333333333333333333333333333"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUX7LWLUIvFu"
      },
      "outputs": [],
      "source": [
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "# Function to train the QNN model for one client\n",
        "def train_qnn_model(client_data,client_test_data, model=None):\n",
        "    #num_features = client_data[0][\"sequence\"].shape[0]  # Get the feature dimension\n",
        "    # Debug: Print the client data structure\n",
        "    print(\"Client Test Data Structure:\", client_test_data)\n",
        "    if model is None:\n",
        "        # Create a new QNN model if one doesn't exist\n",
        "        model = create_qnn_model(client_data)\n",
        "\n",
        "    # Extract sequences and labels for training\n",
        "    train_sequences = [data_point[\"sequence\"] for data_point in client_data]\n",
        "    train_labels = [data_point[\"label\"] for data_point in client_data]\n",
        "\n",
        "    # Extract sequences and labels for testing\n",
        "    # Handle test data\n",
        "    if isinstance(client_test_data, dict):\n",
        "        # Single data point (dictionary format)\n",
        "        test_sequences = np.array([client_test_data[\"sequence\"]])\n",
        "        test_labels = np.array([client_test_data[\"label\"]])\n",
        "    else:\n",
        "        # List of dictionaries (multiple data points)\n",
        "        test_sequences = [data_point[\"sequence\"] for data_point in client_test_data]\n",
        "        test_labels = [data_point[\"label\"] for data_point in client_test_data]\n",
        "        test_sequences = np.array(test_sequences)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    train_sequences = np.array(train_sequences)\n",
        "    train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "    print(\"Training started...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the QNN model\n",
        "    model.fit(train_sequences, train_labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training completed in {elapsed_time} seconds.\")\n",
        "\n",
        "    # Evaluate the model on training and test data\n",
        "    train_score_q = model.score(train_sequences, train_labels)\n",
        "    test_score_q = model.score(test_sequences, test_labels)\n",
        "\n",
        "    return model, train_score_q, test_score_q, elapsed_time\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch], model=client.primary_model)\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"  \")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        for model in client.models:\n",
        "        # Extract numerical values of parameters (as a NumPy array)\n",
        "            param_values = [p.value for p in model.neural_network.circuit.parameters] # Extract the values\n",
        "            epoch_weights.append(param_values)\n",
        "\n",
        "    # Average the numerical values of the parameters across clients\n",
        "    average_weights = np.mean(epoch_weights, axis=0)\n",
        "\n",
        "    # Manually update each client's model parameters with the averaged weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    for client in clients:\n",
        "        # Manually set the global averaged weights to the model's parameters\n",
        "        for i, param in enumerate(client.primary_model.neural_network.circuit.parameters):\n",
        "            client.primary_model.neural_network.circuit._parameters[param] = average_weights[i] # Set the value directly\n",
        "\n",
        "\n",
        "    # Calculate global accuracy\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "\n",
        "    # Print global accuracy for the epoch\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqzOZRiKN2FE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "itr = 0\n",
        "def training_callback(weights, obj_func_eval):\n",
        "        global itr\n",
        "        itr += 1\n",
        "        print(f\"{itr}\", end=' | ')\n",
        "def train(data, model = None):\n",
        "  if model is None:\n",
        "    num_features = len(data[0][\"sequence\"])\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "    optimizer = COBYLA(maxiter=max_train_iterations)\n",
        "    vqc_model = VQC(\n",
        "        feature_map=feature_map,\n",
        "        ansatz=ansatz,\n",
        "        optimizer=optimizer,\n",
        "        callback=partial(training_callback),\n",
        "        sampler=BackendSampler(backend=backend),\n",
        "        warm_start=True\n",
        "    )\n",
        "    model = vqc_model\n",
        "\n",
        "  train_sequences = [data_point[\"sequence\"] for data_point in data]\n",
        "  train_labels = [data_point[\"label\"] for data_point in data]\n",
        "\n",
        "  # Convert the lists to NumPy arrays\n",
        "  train_sequences = np.array(train_sequences)\n",
        "  train_labels = np.array(train_labels)\n",
        "\n",
        "  # Print the shapes\n",
        "  print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "  print(\"Train Labels Shape:\", train_labels.shape)\n",
        "\n",
        "  print(\"Training Started\")\n",
        "  start_time = time.time()\n",
        "  model.fit(train_sequences, train_labels)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nTraining complete. Time taken: {elapsed_time} seconds.\")\n",
        "\n",
        "  print(f\"SCORING MODEL\")\n",
        "  train_score_q = model.score(train_sequences, train_labels)\n",
        "  test_score_q = model.score(test_sequences[:200], test_labels[:200])\n",
        "  return train_score_q, test_score_q, model\n",
        "\n",
        "def getAccuracy(weights):\n",
        "        num_features = len(test_sequences[0])\n",
        "        feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "        ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "        ansatz = ansatz.bind_parameters(weights)\n",
        "        optimizer = COBYLA(maxiter=0)\n",
        "        vqc = VQC(\n",
        "            feature_map=feature_map,\n",
        "            ansatz=ansatz,\n",
        "            optimizer=optimizer,\n",
        "            sampler=BackendSampler(backend=backend)\n",
        "        )\n",
        "        vqc.fit(test_sequences[:25], test_labels[:25])\n",
        "        return vqc.score(test_sequences[:200], test_labels[:200])\n",
        "\n",
        "def create_model_with_weights(weights):\n",
        "  num_features = len(test_sequences[0])\n",
        "  feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "  ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "  optimizer = COBYLA(maxiter=max_train_iterations)\n",
        "  vqc = VQC(\n",
        "      feature_map=feature_map,\n",
        "      ansatz=ansatz,\n",
        "      optimizer=optimizer,\n",
        "      sampler=BackendSampler(backend=backend),\n",
        "      warm_start = True,\n",
        "      initial_point  = weights,\n",
        "      callback=partial(training_callback)\n",
        "  )\n",
        "  return vqc\n",
        "\n",
        "\n",
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  global_model_weights[epoch] = []\n",
        "  epoch_weights = []\n",
        "  print(f\"epoch: {epoch}\")\n",
        "  for index, client in enumerate(clients):\n",
        "    print(f\"Index: {index}, Client: {client}\")\n",
        "\n",
        "    if client.primary_model is None:\n",
        "      train_score_q, test_score_q, model = train(data = client.data[epoch])\n",
        "      client.models.append(model)\n",
        "      client.test_scores.append(test_score_q)\n",
        "      client.train_scores.append(train_score_q)\n",
        "      # Print the values\n",
        "      print(\"Train Score:\", train_score_q)\n",
        "      print(\"Test Score:\", test_score_q)\n",
        "      print(\"\\n\\n\")\n",
        "      epoch_weights.append(model.weights)\n",
        "\n",
        "    else:\n",
        "      train_score_q, test_score_q, model = train(data = client.data[epoch], model = client.primary_model)\n",
        "      client.models.append(model)\n",
        "      client.test_scores.append(test_score_q)\n",
        "      client.train_scores.append(train_score_q)\n",
        "      print(\"Train Score:\", train_score_q)\n",
        "      print(\"Test Score:\", test_score_q)\n",
        "      print(\"\\n\\n\")\n",
        "      epoch_weights.append(model.weights)\n",
        "\n",
        "\n",
        "if(epoch != 0):\n",
        "    epoch_weights.append(global_model_weights[epoch-1])\n",
        "average_weights = sum(epoch_weights) / len(epoch_weights)\n",
        "\n",
        "global_model_weights[epoch] = average_weights\n",
        "new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch])\n",
        "for index, client in enumerate(clients):\n",
        "  client.primary_model = new_model_with_global_weights\n",
        "\n",
        "global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy}\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "global_model_accuracy.append(global_accuracy)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZmf/Zy79A4Uo8qh2IG+Wg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}