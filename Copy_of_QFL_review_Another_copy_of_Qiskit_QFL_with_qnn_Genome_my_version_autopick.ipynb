{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanikairoshi/QFL_Experiments/blob/main/Copy_of_QFL_review_Another_copy_of_Qiskit_QFL_with_qnn_Genome_my_version_autopick.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdPhLlT9q3Np"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Us3DV6Sfq6Mw"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%capture\n",
        "!pip install genomic-benchmarks\n",
        "!pip install qiskit qiskit_machine_learning qiskit_algorithms\n",
        "!pip install qiskit-aer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "from genomic_benchmarks.dataset_getters.pytorch_datasets import DemoHumanOrWorm\n",
        "\n",
        "test_set = DemoHumanOrWorm(split='test', version=0)\n",
        "train_set = DemoHumanOrWorm(split='train', version=0)\n",
        "\n",
        "data_set = train_set\n",
        "# data_set = train_set + test_set\n",
        "len(data_set)\n",
        "\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "word_size = 40\n",
        "word_combinations = defaultdict(int)\n",
        "iteration = 1\n",
        "for text, _ in data_set:\n",
        "    for i in range(len(text)):\n",
        "        word = text[i:i+word_size]\n",
        "        if word_combinations.get(word) is None:\n",
        "          word_combinations[word] = iteration\n",
        "          iteration += 1\n",
        "\n",
        "\n",
        "\n",
        "print(\"First sample int the data_set variable: \")\n",
        "print(data_set[0])\n",
        "\n",
        "print(\"\\nFirst 5 samples in the word_combinations dict.\")\n",
        "for key, value in list(word_combinations.items())[:5]:\n",
        "    print(key, value)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "# Preprocess the training set\n",
        "np_data_set = []\n",
        "for i in range(len(data_set)):\n",
        "    sequence, label = data_set[i]\n",
        "    sequence = sequence.strip()  # Remove any leading/trailing whitespace\n",
        "    words = [sequence[i:i + word_size] for i in range(0, len(sequence), word_size)]  # Split the sequence into 4-letter words\n",
        "    int_sequence = np.array([word_combinations[word] for word in words])\n",
        "    data_point = {'sequence': int_sequence, 'label': label}\n",
        "    np_data_set.append(data_point)\n",
        "\n",
        "\n",
        "print(\"First 5 samples of encoded data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np.random.shuffle(np_data_set)\n",
        "print(\"First 5 samples of encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sequences = np.array([item['sequence'] for item in np_data_set])\n",
        "sequences = np.vstack(sequences)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "sequences_scaled = scaler.fit_transform(sequences)\n",
        "\n",
        "for i, item in enumerate(np_data_set):\n",
        "    item['sequence'] = sequences_scaled[i]\n",
        "\n",
        "print(\"First 5 samples of scaled encoded shuffled data:\")\n",
        "np_data_set[:5]\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:70000]\n",
        "np_test_data = np_data_set[-5000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np_train_data = np_data_set[:70000]\n",
        "np_test_data = np_data_set[-5000:]\n",
        "\n",
        "print(f\"Length of np_train_data: {len(np_train_data)}\")\n",
        "print(f\"Length of np_test_data: {len(np_test_data)}\")\n",
        "\n",
        "test_sequences = [data_point[\"sequence\"] for data_point in np_test_data]\n",
        "test_labels = [data_point[\"label\"] for data_point in np_test_data]\n",
        "test_sequences = np.array(test_sequences)\n",
        "test_labels = np.array(test_labels)\n",
        "print(f\"Length of Test data: {len(test_sequences)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r4S1g9FC5nH",
        "outputId": "f40c53d1-3ebb-4411-ee1a-68ddee69d880"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/genomic_benchmarks/utils/datasets.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First sample int the data_set variable: \n",
            "('TTTTAATTCTTCATTTTCCAGCACAGAAGACTTCACCCAGATTCCCTGCTGCCATTTTTATTTCCAGCCATTATGGAAACCCTGGAAAATGCAGGGTCTGCGGAAGTGAGGACAGACCCTCACCCCCAGTGGTGCCAACAGAACAGTAATCACAGGAGCTGCGGAGCCATCCCAGAGTAGCCTCCACAATTAATTGCAGG', 0)\n",
            "\n",
            "First 5 samples in the word_combinations dict.\n",
            "TTTTAATTCTTCATTTTCCAGCACAGAAGACTTCACCCAG 1\n",
            "TTTAATTCTTCATTTTCCAGCACAGAAGACTTCACCCAGA 2\n",
            "TTAATTCTTCATTTTCCAGCACAGAAGACTTCACCCAGAT 3\n",
            "TAATTCTTCATTTTCCAGCACAGAAGACTTCACCCAGATT 4\n",
            "AATTCTTCATTTTCCAGCACAGAAGACTTCACCCAGATTC 5\n",
            "First 5 samples of encoded data:\n",
            "First 5 samples of encoded shuffled data:\n",
            "First 5 samples of scaled encoded shuffled data:\n",
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of Test data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcRZf8-bLOQH",
        "outputId": "d7a35fa4-10f5-4346-c298-c39ae82d651a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of np_train_data: 70000\n",
            "Length of np_test_data: 5000\n",
            "Length of Test data: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the structure of np_test_data\n",
        "for i, data_point in enumerate(np_test_data[:5]):  # Print the first 5 test data points\n",
        "    print(f\"Test data point {i}: {data_point}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTLOJOQeLRg7",
        "outputId": "cb0f4c08-0495-4adb-d6cc-dd0c117d626b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data point 0: {'sequence': array([0.73816034, 0.73816034, 0.73816034, 0.73816034, 0.73816034]), 'label': 1}\n",
            "Test data point 1: {'sequence': array([0.54409911, 0.54409911, 0.54409911, 0.54409911, 0.54409911]), 'label': 1}\n",
            "Test data point 2: {'sequence': array([0.04371044, 0.04371044, 0.04371044, 0.04371044, 0.04371044]), 'label': 0}\n",
            "Test data point 3: {'sequence': array([0.41804649, 0.41804649, 0.41804649, 0.41804649, 0.41804649]), 'label': 0}\n",
            "Test data point 4: {'sequence': array([0.46790039, 0.46790039, 0.46790039, 0.46790039, 0.46790039]), 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vM9FXroZu1bK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.primitives import BackendSampler\n",
        "from functools import partial\n",
        "from qiskit_aer import Aer\n",
        "\n",
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "num_clients = 5\n",
        "num_epochs = 20\n",
        "max_train_iterations = 50\n",
        "samples_per_epoch=100\n",
        "backend = Aer.get_backend('aer_simulator')\n",
        "\n",
        "class Client:\n",
        "   def __init__(self, train_data):  # Add test_data to __init__\n",
        "        self.client_train_data = train_data\n",
        "        #self.test_data = test_data  # Store test_data as an attribute\n",
        "        self.models = []\n",
        "        self.train_scores = []\n",
        "        self.test_scores = []\n",
        "        self.primary_model = None\n",
        "'''\n",
        "def split_dataset(num_clients, num_epochs, samples_per_epoch):\n",
        "  clients = []\n",
        "  for i in range(num_clients):\n",
        "    client_data = []\n",
        "    for j in range(num_epochs):\n",
        "      start_idx = (i*num_epochs*samples_per_epoch)+(j*samples_per_epoch)\n",
        "      end_idx = (i*num_epochs*samples_per_epoch)+((j+1)*samples_per_epoch)\n",
        "      client_data.append(np_train_data[start_idx:end_idx])\n",
        "    # Pass test_data when creating Client instances\n",
        "    clients.append(Client(client_data, np_test_data))\n",
        "  return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "'''\n",
        "def split_dataset(num_clients, num_epochs, samples_per_epoch):\n",
        "    clients = []\n",
        "    # Split test data across clients\n",
        "    #test_samples_per_client = len(test_sample_sequences) // num_clients\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_train_data = []\n",
        "        for j in range(num_epochs):\n",
        "            start_idx = (i * num_epochs * samples_per_epoch) + (j * samples_per_epoch)\n",
        "            end_idx = (i * num_epochs * samples_per_epoch) + ((j + 1) * samples_per_epoch)\n",
        "            client_train_data.append(np_train_data[start_idx:end_idx])\n",
        "            #print(f\"Client {i+1} training data size: {len(np_train_data[start_idx:end_idx])}\")\n",
        "        # Assign a subset of the test data to each client\n",
        "        #test_start_idx = i * test_samples_per_client\n",
        "        #test_end_idx = (i + 1) * test_samples_per_client\n",
        "        #client_test_data = test_sample_sequences[test_start_idx:test_end_idx]\n",
        "\n",
        "        # Create Client instance with both train and test data\n",
        "        clients.append(Client(client_train_data))\n",
        "\n",
        "    return clients\n",
        "\n",
        "clients = split_dataset(num_clients, num_epochs, samples_per_epoch)\n",
        "\n",
        "itr = 0\n",
        "def training_callback(weights, obj_func_eval):\n",
        "        global itr\n",
        "        itr += 1\n",
        "        print(f\"{itr}\", end=' | ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_AV8hy8zY_R"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vMGbsnFLzZhB"
      },
      "outputs": [],
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Callback function to visualize training progress\n",
        "objective_func_vals = []\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SE9YYRwPJDau"
      },
      "outputs": [],
      "source": [
        "# Function to initialize a new QNN model (same architecture as clients' models)\n",
        "def initialize_model(num_features):\n",
        "    # Create the same quantum neural network (QNN) architecture as clients\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Combine the feature map and ansatz into a single quantum circuit\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Input parameters (for encoding)\n",
        "    weight_params = ansatz.parameters      # Trainable parameters (for optimization)\n",
        "\n",
        "    # Define the QNN model using a sampler\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Binary classification\n",
        "        input_params=input_params,\n",
        "        weight_params=weight_params\n",
        "    )\n",
        "\n",
        "    # Create a classifier using the neural network\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50)  # Use SPSA optimizer\n",
        "    )\n",
        "\n",
        "    return qnn_classifier\n",
        "\n",
        "# Function to create a model with averaged weights\n",
        "def create_model_with_weights(average_weights, num_features):\n",
        "    # Initialize a new QNN model with the same architecture\n",
        "    model = initialize_model(num_features)\n",
        "    # Assign the averaged weights to the model's trainable parameters (ansatz weights)\n",
        "    weight_params = model.neural_network.weight_params  # Get the trainable parameters\n",
        "\n",
        "    # Check if the lengths match, and truncate if necessary\n",
        "    num_weights = min(len(average_weights), len(weight_params))\n",
        "\n",
        "    # Create a dictionary mapping parameters to averaged weights\n",
        "    param_dict = {param: average_weights[i] for i, param in enumerate(weight_params[:num_weights])}\n",
        "\n",
        "\n",
        "    # Assign the averaged weights to the circuit parameters\n",
        "    model.neural_network.circuit.assign_parameters(param_dict)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j-HD-sL2zgxh"
      },
      "outputs": [],
      "source": [
        "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
        "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
        "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes\n",
        "from qiskit.primitives import BackendSampler\n",
        "from qiskit_algorithms.optimizers import SPSA\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Callback function to visualize training progress\n",
        "objective_func_vals = []\n",
        "def callback_graph(weights, obj_func_eval):\n",
        "    clear_output(wait=True)\n",
        "    objective_func_vals.append(obj_func_eval)\n",
        "    plt.title(\"Objective function value against iteration\")\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"Objective function value\")\n",
        "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
        "    plt.show()\n",
        "\n",
        "# Function to create the QNN model\n",
        "def create_qnn_model(num_features):\n",
        "    # num_features = data_train[0][\"sequence\"].shape[0]  # Remove this line as data_train is not defined\n",
        "    # Define the quantum feature map and ansatz\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)  # Use num_features passed as argument\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Construct the quantum neural network using a sampler\n",
        "    qc = feature_map.compose(ansatz)  # Build the QNN circuit\n",
        "    print(f\"Number of features (input dimension): {num_features}\")\n",
        "    print(f\"Number of circuit parameters: {qc.num_parameters}\")\n",
        "\n",
        "    # Use parity as the interpretation function\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2  # Binary classification\n",
        "\n",
        "    # Explicitly define input_params and weight_params\n",
        "    input_params = feature_map.parameters  # Parameters for the feature map (inputs)\n",
        "    weight_params = ansatz.parameters      # Parameters for the ansatz (weights)\n",
        "    #print(f\"Input Parameters: {input_params}\")\n",
        "    #print(f\"Weight Parameters: {weight_params}\")\n",
        "\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Output dimension for binary classification\n",
        "        input_params=input_params,       # Pass input parameters\n",
        "        weight_params=weight_params     # Pass weight parameters\n",
        "    )\n",
        "\n",
        "    # Define a classifier using the QNN\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=SPSA(maxiter=50),  # Example with SPSA optimizer\n",
        "        #callback=callback_graph\n",
        "    )\n",
        "\n",
        "    return qnn_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IkECBNFLazNA"
      },
      "outputs": [],
      "source": [
        "def getAccuracy(weights, num_features, test_sequences, test_labels):\n",
        "    # Rebuild the QNN model with the given weights\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "\n",
        "    # Replace bind_parameters with assign_parameters\n",
        "    # Create a parameter dictionary for assignment\n",
        "    param_dict = {param: weight for param, weight in zip(ansatz.parameters, weights)}\n",
        "    ansatz = ansatz.assign_parameters(param_dict)\n",
        "\n",
        "    # Rebuild the QNN using the updated ansatz\n",
        "    qc = feature_map.compose(ansatz)\n",
        "\n",
        "    # Define the parity function for binary classification\n",
        "    def parity(x):\n",
        "        return \"{:b}\".format(x).count(\"1\") % 2\n",
        "\n",
        "    # Build the SamplerQNN with the updated circuit\n",
        "    sampler_qnn = SamplerQNN(\n",
        "        circuit=qc,\n",
        "        interpret=parity,\n",
        "        output_shape=2,  # Binary classification\n",
        "        input_params=feature_map.parameters,  # Input parameters (from the feature map)\n",
        "        weight_params=ansatz.parameters  # Weight parameters (from the ansatz)\n",
        "    )\n",
        "\n",
        "    # Build the NeuralNetworkClassifier with the QNN\n",
        "    qnn_classifier = NeuralNetworkClassifier(\n",
        "        neural_network=sampler_qnn,\n",
        "        optimizer=COBYLA(maxiter=0)  # No need for further optimization\n",
        "    )\n",
        "\n",
        "    # Train the classifier on a subset of test data (or use full test data if preferred)\n",
        "    qnn_classifier.fit(test_sequences, test_labels)\n",
        "\n",
        "    # Return the accuracy on a larger test set\n",
        "    return qnn_classifier.score(test_sequences, test_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CSV_PATH = '/content/drive/MyDrive/QFL_folder/federated_qnn_metrics_genome_autopick.csv'  # change if you like\n",
        "os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "def init_metrics_csv(csv_path: str, num_clients: int):\n",
        "    \"\"\"Create/overwrite CSV with a header.\"\"\"\n",
        "    header = ['Epoch', 'GlobalAccuracy']\n",
        "    for i in range(num_clients):\n",
        "        header += [f'Client{i}_TrainAcc', f'Client{i}_TestAcc']\n",
        "    with open(csv_path, 'w', newline='') as f:\n",
        "        csv.writer(f).writerow(header)\n",
        "\n",
        "def append_metrics_row(csv_path: str, epoch: int, global_acc: float,\n",
        "                       train_accs: list[float], test_accs: list[float]):\n",
        "    \"\"\"Append one epoch’s metrics.\"\"\"\n",
        "    row = [epoch, global_acc] + [\n",
        "        x for pair in zip(train_accs, test_accs) for x in pair\n",
        "    ]\n",
        "    with open(csv_path, 'a', newline='') as f:\n",
        "        csv.writer(f).writerow(row)\n",
        "\n",
        "def compute_global_accuracy(model, clients: list[dict]) -> float:\n",
        "    \"\"\"Evaluate the current global model on the union of all client test sets.\"\"\"\n",
        "    X = np.concatenate([c[\"test_data\"][\"sequence\"] for c in clients], axis=0)\n",
        "    y = np.concatenate([c[\"test_data\"][\"label\"]   for c in clients],   axis=0)\n",
        "    return float(model.score(X, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTktmHkiuWhn",
        "outputId": "2d307f36-7d26-49f6-d5eb-0403b82e4849"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Optional, Tuple, Dict\n",
        "\n",
        "# ---------- Angle utilities ----------\n",
        "def _wrap_to_pi(x: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Map real numbers to (-π, π].\"\"\"\n",
        "    return (x + np.pi) % (2*np.pi) - np.pi\n",
        "\n",
        "def _unwrap_to_ref(A: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Unwrap rows to be closest to the first row (reference).\n",
        "    A: (K, D) angles in (-π, π].\n",
        "    \"\"\"\n",
        "    K, D = A.shape\n",
        "    out = A.copy()\n",
        "    ref = out[0]\n",
        "    for i in range(1, K):\n",
        "        delta = out[i] - ref\n",
        "        out[i] = ref + ((delta + np.pi) % (2*np.pi) - np.pi)\n",
        "    return out\n",
        "\n",
        "def _weighted_circular_mean(A: np.ndarray, W: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Coordinate-wise weighted circular mean.\n",
        "    A: (K, D) in (-π, π]; W: (K,), sum=1.\n",
        "    \"\"\"\n",
        "    C = np.sum(W[:, None] * np.cos(A), axis=0)\n",
        "    S = np.sum(W[:, None] * np.sin(A), axis=0)\n",
        "    return np.arctan2(S, C)\n",
        "\n",
        "def _geodesic_sse(angles: np.ndarray, center: np.ndarray, W: np.ndarray) -> float:\n",
        "    \"\"\"Weighted sum of squared geodesic distances (torus).\"\"\"\n",
        "    diff = _wrap_to_pi(angles - center)    # (K, D)\n",
        "    sse_per_client = np.sum(diff**2, axis=1)\n",
        "    return float(np.sum(W * sse_per_client))\n",
        "\n",
        "def _min_covering_arc_length(angles_1d: np.ndarray) -> float:\n",
        "    \"\"\"Minimal arc length covering all angles in [0, 2π] metric.\"\"\"\n",
        "    a = np.sort(angles_1d)\n",
        "    gaps = np.diff(a, append=a[0] + 2*np.pi)\n",
        "    return float(2*np.pi - np.max(gaps))\n",
        "\n",
        "def angle_diagnostics(local_ws: List[np.ndarray], shard_sizes: List[int]) -> Dict[str, object]:\n",
        "    \"\"\"\n",
        "    Interpret local_ws as angles in (-π, π]; return summary stats for auto-pick.\n",
        "    \"\"\"\n",
        "    A = np.stack(local_ws, axis=0)                 # (K, D)\n",
        "    W = np.asarray(shard_sizes, float)\n",
        "    W /= W.sum()\n",
        "\n",
        "    C = np.sum(W[:, None] * np.cos(A), axis=0)\n",
        "    S = np.sum(W[:, None] * np.sin(A), axis=0)\n",
        "    R = np.sqrt(C**2 + S**2)\n",
        "    R_mean = float(np.mean(R))\n",
        "    R_min  = float(np.min(R))\n",
        "\n",
        "    mu_circ = np.arctan2(S, C)\n",
        "    A_unwrap = _unwrap_to_ref(A)\n",
        "    mu_lin_unwrapped = np.sum(W[:, None] * A_unwrap, axis=0)\n",
        "    mu_lin = _wrap_to_pi(mu_lin_unwrapped)\n",
        "\n",
        "    sse_circ = _geodesic_sse(A, mu_circ, W)\n",
        "    sse_lin  = _geodesic_sse(A, mu_lin,  W)\n",
        "    sse_gap  = float(sse_lin - sse_circ)  # > 0 ⇒ circular better intrinsically\n",
        "\n",
        "    cover = np.array([_min_covering_arc_length(A[:, j]) for j in range(A.shape[1])])\n",
        "    straddle_frac = float(1.0 - np.mean(cover <= np.pi))\n",
        "\n",
        "    return {\n",
        "        \"R_mean\": R_mean,\n",
        "        \"R_min\": R_min,\n",
        "        \"straddle_frac\": straddle_frac,\n",
        "        \"sse_geo_gap\": sse_gap,\n",
        "        \"mu_circ\": mu_circ,\n",
        "        \"mu_lin\":  mu_lin,\n",
        "    }\n",
        "\n",
        "# ---------- Aggregators ----------\n",
        "def fedavg_linear(local_ws: List[np.ndarray], shard_sizes: List[int]) -> np.ndarray:\n",
        "    W = np.asarray(shard_sizes, float); W /= W.sum()\n",
        "    A = np.stack(local_ws, axis=0)                 # (K, D)\n",
        "    return np.sum(W[:, None] * A, axis=0)\n",
        "\n",
        "def fedavg_circular(local_ws: List[np.ndarray], shard_sizes: List[int]) -> np.ndarray:\n",
        "    W = np.asarray(shard_sizes, float); W /= W.sum()\n",
        "    A = np.stack(local_ws, axis=0)                 # (K, D) angles\n",
        "    return _weighted_circular_mean(A, W)\n",
        "\n",
        "def _autopick_mode(diag: Dict[str, object],\n",
        "                   r_mean_thresh: float = 0.85,\n",
        "                   straddle_thresh: float = 0.05) -> str:\n",
        "    \"\"\"\n",
        "    Rule: prefer circular if geodesic SSE gap > 0, or straddling occurs, or concentration is low.\n",
        "    \"\"\"\n",
        "    if (diag[\"sse_geo_gap\"] > 0.0) or (diag[\"straddle_frac\"] > straddle_thresh) or (diag[\"R_mean\"] < r_mean_thresh):\n",
        "        return \"circular\"\n",
        "    return \"linear\"\n",
        "\n",
        "def aggregate_weights_angle_aware(\n",
        "    local_ws: List[np.ndarray],\n",
        "    shard_sizes: List[int],\n",
        "    mode: str = \"auto\",\n",
        "    angle_mask: Optional[np.ndarray] = None\n",
        ") -> Tuple[np.ndarray, Dict[str, object]]:\n",
        "    \"\"\"\n",
        "    Angle-aware aggregation on a mixed parameter vector.\n",
        "    - local_ws: list of client vectors (length D)\n",
        "    - shard_sizes: client weights (e.g., data counts)\n",
        "    - mode ∈ {'linear','circular','auto'}\n",
        "    - angle_mask: boolean mask of length D; True ⇒ treat as angle in (-π, π]\n",
        "    Returns: (avg_weights, diagnostics)\n",
        "    \"\"\"\n",
        "    A = np.stack(local_ws, axis=0)                 # (K, D)\n",
        "    D = A.shape[1]\n",
        "    W = np.asarray(shard_sizes, float); W /= W.sum()\n",
        "\n",
        "    if angle_mask is None:\n",
        "        # If you only have circuit angles in 'weights', set all True.\n",
        "        angle_mask = np.ones(D, dtype=bool)\n",
        "\n",
        "    ang_idx = angle_mask\n",
        "    non_idx = ~angle_mask\n",
        "\n",
        "    diag = {\"used_mode\": None}\n",
        "    if np.any(ang_idx):\n",
        "        diag_angles = angle_diagnostics([w[ang_idx] for w in local_ws], shard_sizes)\n",
        "    else:\n",
        "        # No angular coordinates ⇒ reduce to linear FedAvg\n",
        "        return fedavg_linear(local_ws, shard_sizes), {\"used_mode\": \"linear\"}\n",
        "\n",
        "    pick = mode if mode != \"auto\" else _autopick_mode(diag_angles)\n",
        "\n",
        "    out = np.zeros(D, dtype=float)\n",
        "    if pick == \"linear\":\n",
        "        out[:] = fedavg_linear(local_ws, shard_sizes)\n",
        "    elif pick == \"circular\":\n",
        "        circ = fedavg_circular([w[ang_idx] for w in local_ws], shard_sizes)\n",
        "        out[ang_idx] = _wrap_to_pi(circ)\n",
        "        if np.any(non_idx):\n",
        "            out[non_idx] = fedavg_linear([w[non_idx] for w in local_ws], shard_sizes)\n",
        "    else:\n",
        "        raise ValueError(\"mode must be one of {'linear','circular','auto'}\")\n",
        "\n",
        "    diag.update(diag_angles)\n",
        "    diag[\"used_mode\"] = pick\n",
        "    return out, diag\n"
      ],
      "metadata": {
        "id": "1m114jkZ7t9Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ucS5zEozmN5",
        "outputId": "22a5ce60-74e1-469a-b448-485eee9a9fbe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Training Client 0\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 124.46851539611816 seconds.\n",
            "Client 0 Train Score: 0.83\n",
            "Client 0 Test Score: 0.7546\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 123.45888757705688 seconds.\n",
            "Client 1 Train Score: 0.75\n",
            "Client 1 Test Score: 0.7426\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 123.55205345153809 seconds.\n",
            "Client 2 Train Score: 0.8\n",
            "Client 2 Test Score: 0.7038\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 123.50706148147583 seconds.\n",
            "Client 3 Train Score: 0.86\n",
            "Client 3 Test Score: 0.7926\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Number of features (input dimension): 5\n",
            "Number of circuit parameters: 25\n",
            "Training started...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3714545703.py:44: DeprecationWarning: V1 Primitives are deprecated as of qiskit-machine-learning 0.8.0 and will be removed no sooner than 4 months after the release date. Use V2 primitives for continued compatibility and support.\n",
            "  sampler_qnn = SamplerQNN(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed in 123.36955547332764 seconds.\n",
            "Client 4 Train Score: 0.81\n",
            "Client 4 Test Score: 0.8186\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.555 | straddle=0.300 | sse_gap=2.7741\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 0] global_acc=0.5220 | train=[0.83, 0.75, 0.8, 0.86, 0.81] | test=[0.7546, 0.7426, 0.7038, 0.7926, 0.8186]\n",
            "Epoch: 1\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 124.53744292259216 seconds.\n",
            "Client 0 Train Score: 0.87\n",
            "Client 0 Test Score: 0.8248\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 125.41923141479492 seconds.\n",
            "Client 1 Train Score: 0.77\n",
            "Client 1 Test Score: 0.6396\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 125.04761719703674 seconds.\n",
            "Client 2 Train Score: 0.85\n",
            "Client 2 Test Score: 0.7498\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 123.5083920955658 seconds.\n",
            "Client 3 Train Score: 0.75\n",
            "Client 3 Test Score: 0.7098\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 125.00794649124146 seconds.\n",
            "Client 4 Train Score: 0.75\n",
            "Client 4 Test Score: 0.779\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.713 | straddle=0.150 | sse_gap=-0.2243\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 1] global_acc=0.7400 | train=[0.87, 0.77, 0.85, 0.75, 0.75] | test=[0.8248, 0.6396, 0.7498, 0.7098, 0.779]\n",
            "Epoch: 2\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 124.38807153701782 seconds.\n",
            "Client 0 Train Score: 0.78\n",
            "Client 0 Test Score: 0.7688\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 121.99430322647095 seconds.\n",
            "Client 1 Train Score: 0.82\n",
            "Client 1 Test Score: 0.7878\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 124.05689644813538 seconds.\n",
            "Client 2 Train Score: 0.82\n",
            "Client 2 Test Score: 0.8148\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 122.18799352645874 seconds.\n",
            "Client 3 Train Score: 0.71\n",
            "Client 3 Test Score: 0.6966\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 124.50916385650635 seconds.\n",
            "Client 4 Train Score: 0.72\n",
            "Client 4 Test Score: 0.6028\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.504 | straddle=0.400 | sse_gap=4.3782\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 2] global_acc=0.4720 | train=[0.78, 0.82, 0.82, 0.71, 0.72] | test=[0.7688, 0.7878, 0.8148, 0.6966, 0.6028]\n",
            "Epoch: 3\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 125.1272087097168 seconds.\n",
            "Client 0 Train Score: 0.81\n",
            "Client 0 Test Score: 0.7118\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 123.04874038696289 seconds.\n",
            "Client 1 Train Score: 0.83\n",
            "Client 1 Test Score: 0.8052\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 122.41391515731812 seconds.\n",
            "Client 2 Train Score: 0.8\n",
            "Client 2 Test Score: 0.7068\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 124.1810040473938 seconds.\n",
            "Client 3 Train Score: 0.78\n",
            "Client 3 Test Score: 0.7248\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 125.71333122253418 seconds.\n",
            "Client 4 Train Score: 0.71\n",
            "Client 4 Test Score: 0.6922\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.606 | straddle=0.350 | sse_gap=3.7694\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 3] global_acc=0.4440 | train=[0.81, 0.83, 0.8, 0.78, 0.71] | test=[0.7118, 0.8052, 0.7068, 0.7248, 0.6922]\n",
            "Epoch: 4\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 122.62221026420593 seconds.\n",
            "Client 0 Train Score: 0.77\n",
            "Client 0 Test Score: 0.7254\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 123.78655409812927 seconds.\n",
            "Client 1 Train Score: 0.81\n",
            "Client 1 Test Score: 0.8242\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 122.9935462474823 seconds.\n",
            "Client 2 Train Score: 0.78\n",
            "Client 2 Test Score: 0.717\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 123.88085079193115 seconds.\n",
            "Client 3 Train Score: 0.89\n",
            "Client 3 Test Score: 0.8854\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 124.86590123176575 seconds.\n",
            "Client 4 Train Score: 0.85\n",
            "Client 4 Test Score: 0.853\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.543 | straddle=0.400 | sse_gap=6.5821\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 4] global_acc=0.5720 | train=[0.77, 0.81, 0.78, 0.89, 0.85] | test=[0.7254, 0.8242, 0.717, 0.8854, 0.853]\n",
            "Epoch: 5\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 123.99333190917969 seconds.\n",
            "Client 0 Train Score: 0.62\n",
            "Client 0 Test Score: 0.6918\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 121.83350157737732 seconds.\n",
            "Client 1 Train Score: 0.8\n",
            "Client 1 Test Score: 0.8302\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 124.94580554962158 seconds.\n",
            "Client 2 Train Score: 0.65\n",
            "Client 2 Test Score: 0.6208\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 124.76881861686707 seconds.\n",
            "Client 3 Train Score: 0.63\n",
            "Client 3 Test Score: 0.6064\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 124.80284476280212 seconds.\n",
            "Client 4 Train Score: 0.85\n",
            "Client 4 Test Score: 0.7824\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.404 | straddle=0.650 | sse_gap=3.0387\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 5] global_acc=0.5820 | train=[0.62, 0.8, 0.65, 0.63, 0.85] | test=[0.6918, 0.8302, 0.6208, 0.6064, 0.7824]\n",
            "Epoch: 6\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 123.6477689743042 seconds.\n",
            "Client 0 Train Score: 0.64\n",
            "Client 0 Test Score: 0.6154\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 123.04332327842712 seconds.\n",
            "Client 1 Train Score: 0.8\n",
            "Client 1 Test Score: 0.745\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 123.57503366470337 seconds.\n",
            "Client 2 Train Score: 0.76\n",
            "Client 2 Test Score: 0.6952\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 122.41060400009155 seconds.\n",
            "Client 3 Train Score: 0.82\n",
            "Client 3 Test Score: 0.8112\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 125.66348814964294 seconds.\n",
            "Client 4 Train Score: 0.79\n",
            "Client 4 Test Score: 0.7704\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.610 | straddle=0.200 | sse_gap=4.1251\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 6] global_acc=0.6120 | train=[0.64, 0.8, 0.76, 0.82, 0.79] | test=[0.6154, 0.745, 0.6952, 0.8112, 0.7704]\n",
            "Epoch: 7\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 124.83666729927063 seconds.\n",
            "Client 0 Train Score: 0.8\n",
            "Client 0 Test Score: 0.7988\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 126.96827626228333 seconds.\n",
            "Client 1 Train Score: 0.89\n",
            "Client 1 Test Score: 0.9074\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 124.1938464641571 seconds.\n",
            "Client 2 Train Score: 0.82\n",
            "Client 2 Test Score: 0.8172\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 126.08185625076294 seconds.\n",
            "Client 3 Train Score: 0.6\n",
            "Client 3 Test Score: 0.5068\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 122.8871099948883 seconds.\n",
            "Client 4 Train Score: 0.76\n",
            "Client 4 Test Score: 0.7116\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.557 | straddle=0.500 | sse_gap=4.6576\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 7] global_acc=0.4700 | train=[0.8, 0.89, 0.82, 0.6, 0.76] | test=[0.7988, 0.9074, 0.8172, 0.5068, 0.7116]\n",
            "Epoch: 8\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 123.72807240486145 seconds.\n",
            "Client 0 Train Score: 0.9\n",
            "Client 0 Test Score: 0.7954\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 121.39692974090576 seconds.\n",
            "Client 1 Train Score: 0.8\n",
            "Client 1 Test Score: 0.7942\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 122.86687016487122 seconds.\n",
            "Client 2 Train Score: 0.67\n",
            "Client 2 Test Score: 0.6866\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 121.53574395179749 seconds.\n",
            "Client 3 Train Score: 0.92\n",
            "Client 3 Test Score: 0.8988\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 123.58835339546204 seconds.\n",
            "Client 4 Train Score: 0.85\n",
            "Client 4 Test Score: 0.7798\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.460 | straddle=0.650 | sse_gap=4.4807\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 8] global_acc=0.5520 | train=[0.9, 0.8, 0.67, 0.92, 0.85] | test=[0.7954, 0.7942, 0.6866, 0.8988, 0.7798]\n",
            "Epoch: 9\n",
            "Training Client 0\n",
            "Training started...\n",
            "Training completed in 123.0611515045166 seconds.\n",
            "Client 0 Train Score: 0.81\n",
            "Client 0 Test Score: 0.772\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 1\n",
            "Training started...\n",
            "Training completed in 128.73014855384827 seconds.\n",
            "Client 1 Train Score: 0.71\n",
            "Client 1 Test Score: 0.6948\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 2\n",
            "Training started...\n",
            "Training completed in 124.08084797859192 seconds.\n",
            "Client 2 Train Score: 0.8\n",
            "Client 2 Test Score: 0.8046\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 3\n",
            "Training started...\n",
            "Training completed in 126.407639503479 seconds.\n",
            "Client 3 Train Score: 0.85\n",
            "Client 3 Test Score: 0.7978\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "Training Client 4\n",
            "Training started...\n",
            "Training completed in 126.17217421531677 seconds.\n",
            "Client 4 Train Score: 0.8\n",
            "Client 4 Test Score: 0.764\n",
            "\n",
            "\n",
            "\n",
            "----------------------------------------------------------\n",
            "[AUTO] mode=circular | R_mean=0.500 | straddle=0.550 | sse_gap=3.0883\n",
            "Global model updated\n",
            "----------------------------------------------------------\n",
            "[Epoch 9] global_acc=0.4540 | train=[0.81, 0.71, 0.8, 0.85, 0.8] | test=[0.772, 0.6948, 0.8046, 0.7978, 0.764]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Lists to store accuracies over epochs\n",
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "clients_train_accuracies = []  # List to store train accuracies per epoch per client\n",
        "clients_test_accuracies = []   # List to store test accuracies per epoch per client\n",
        "\n",
        "# Function to train the QNN model for one client\n",
        "def train_qnn_model(client_data, client_test_data, model=None):\n",
        "    if model is None:\n",
        "        # Create a new QNN model if one doesn't exist\n",
        "        num_features = client_data[0][\"sequence\"].shape[0]\n",
        "        model = create_qnn_model(num_features)  # Pass num_features\n",
        "\n",
        "    # Extract sequences and labels for training\n",
        "    train_sequences = [data_point[\"sequence\"] for data_point in client_data]\n",
        "    train_labels = [data_point[\"label\"] for data_point in client_data]\n",
        "\n",
        "    # Extract sequences and labels for testing\n",
        "    test_sequences = [data_point[\"sequence\"] for data_point in client_test_data]\n",
        "    test_labels = [data_point[\"label\"] for data_point in client_test_data]\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    train_sequences = np.array(train_sequences)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_sequences = np.array(test_sequences)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    print(\"Training started...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the QNN model\n",
        "    model.fit(train_sequences, train_labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training completed in {elapsed_time} seconds.\")\n",
        "\n",
        "    # Evaluate the model on training and test data\n",
        "    train_score_q = model.score(train_sequences, train_labels)\n",
        "    test_score_q = model.score(test_sequences, test_labels)\n",
        "\n",
        "    return model, train_score_q, test_score_q, elapsed_time\n",
        "\n",
        "# Function to manually average the numerical values of the parameters across clients\n",
        "def manual_average_weights(epoch_weights):\n",
        "    # Initialize a list to store the summed weights (initialize with zeros)\n",
        "    num_weights = len(epoch_weights[0])  # Number of weights in the model\n",
        "    num_clients = len(epoch_weights)  # Number of clients\n",
        "\n",
        "    # Initialize sum of weights to zero (assuming NumPy array or list of weights)\n",
        "    summed_weights = np.zeros(num_weights)\n",
        "\n",
        "    # Sum the weights from all clients\n",
        "    for client_weights in epoch_weights:\n",
        "        summed_weights += np.array(client_weights)\n",
        "\n",
        "    # Compute the average by dividing the summed weights by the number of clients\n",
        "    average_weights = summed_weights / num_clients\n",
        "\n",
        "    return average_weights\n",
        "\n",
        "# Function to save accuracies to CSV\n",
        "def save_accuracies_to_csv(global_accuracies, clients_train_accuracies, clients_test_accuracies, filename='accuracies.csv'):\n",
        "    with open(filename, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "\n",
        "        # Write the header row\n",
        "        header = ['Epoch', 'Global Accuracy']\n",
        "        for i in range(len(clients_train_accuracies[0])):  # Assuming all clients have the same number of records\n",
        "            header.append(f'Client {i} Train Accuracy')\n",
        "            header.append(f'Client {i} Test Accuracy')\n",
        "        writer.writerow(header)\n",
        "\n",
        "        # Write the accuracy data for each epoch\n",
        "        for epoch in range(len(global_accuracies)):\n",
        "            row = [epoch, global_accuracies[epoch]]  # Start with epoch and global accuracy\n",
        "            for client_index in range(len(clients_train_accuracies[epoch])):\n",
        "                row.append(clients_train_accuracies[epoch][client_index])  # Add train accuracy for client\n",
        "                row.append(clients_test_accuracies[epoch][client_index])   # Add test accuracy for client\n",
        "            writer.writerow(row)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def _logits_to_labels(y_raw: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Robust conversion from network outputs to class labels.\"\"\"\n",
        "    y_raw = np.asarray(y_raw)\n",
        "    if y_raw.ndim == 1:\n",
        "        # Binary, single logit (e.g., expectation). Threshold at 0.\n",
        "        return (y_raw >= 0).astype(int)\n",
        "    elif y_raw.ndim == 2:\n",
        "        if y_raw.shape[1] == 1:\n",
        "            return (y_raw[:, 0] >= 0).astype(int)\n",
        "        # Multi-class or 2-class with 2 outputs\n",
        "        return np.argmax(y_raw, axis=1)\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected network output shape: {}\".format(y_raw.shape))\n",
        "\n",
        "\n",
        "def compute_global_accuracy_from_weights(prototype_model, avg_weights: np.ndarray, clients: list) -> float:\n",
        "    \"\"\"\n",
        "    Use a *fitted* prototype_model to access its underlying QNN and\n",
        "    forward the averaged parameter vector 'avg_weights' over the\n",
        "    concatenated global test set, returning accuracy.\n",
        "    \"\"\"\n",
        "    # 1) Build the global test pool\n",
        "    Xg = np.concatenate([np.array(item[\"sequence\"]).reshape(1, -1) for c in clients for item in c.client_train_data[0]], axis=0)\n",
        "    yg = np.concatenate([np.array(item[\"label\"]).reshape(1,) for c in clients for item in c.client_train_data[0]], axis=0)\n",
        "\n",
        "\n",
        "    # 2) Extract the underlying QNN (works for NeuralNetworkClassifier built on {Sampler,Estimator}QNN)\n",
        "    qnn = getattr(prototype_model, \"neural_network\", None)\n",
        "    if qnn is None:\n",
        "        # Some versions use a protected attribute\n",
        "        qnn = getattr(prototype_model, \"_neural_network\", None)\n",
        "    if qnn is None:\n",
        "        raise RuntimeError(\"Cannot access underlying QNN from the classifier.\")\n",
        "\n",
        "    # 3) Forward pass with the *averaged* parameter vector (no fit needed)\n",
        "    y_raw = qnn.forward(Xg, np.asarray(avg_weights))\n",
        "\n",
        "    # 4) Convert to labels and compute accuracy\n",
        "    y_pred = _logits_to_labels(y_raw)\n",
        "    return float(np.mean(y_pred == yg))\n",
        "\n",
        "\n",
        "# Federated learning loop\n",
        "num_features = 5\n",
        "num_epochs = 10\n",
        "global_model_weights = {}\n",
        "\n",
        "num_clients = len(clients)\n",
        "init_metrics_csv(CSV_PATH, num_clients)\n",
        "global_model_accuracy = []\n",
        "# Initialize 'primary_model' for each client\n",
        "for client in clients:  # Assuming 'clients' is your list of client dictionaries\n",
        "    client.primary_model = None  # Initialize 'primary_model' to None\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "\n",
        "    epoch_train_accuracies = []  # Store train accuracies for this epoch\n",
        "    epoch_test_accuracies = []   # Store test accuracies for this epoch\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "        # Use dictionary key access instead of dot notation\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.client_train_data[epoch], np_test_data) # Use client.client_train_data and np_test_data\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.client_train_data[epoch], np_test_data, model=client.primary_model) # Use client.client_train_data and np_test_data\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"\\n\\n\")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        # Append client accuracies for this epoch\n",
        "        epoch_train_accuracies.append(train_score_q)\n",
        "        epoch_test_accuracies.append(test_score_q)\n",
        "\n",
        "        # Collect model weights (assuming model has a \"weights\" attribute that can be averaged)\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "   # Manually compute the average weights\n",
        "    #average_weights = manual_average_weights(epoch_weights)\n",
        "    # Weighted sizes per client (use your own definition of |D_n| as needed)\n",
        "    shard_sizes = [len(client.client_train_data[epoch]) for client in clients]\n",
        "\n",
        "    # If you have a known angle_mask per parameter, pass it here; else None ⇒ all angular.\n",
        "    average_weights, diag = aggregate_weights_angle_aware(\n",
        "        epoch_weights,\n",
        "        shard_sizes=shard_sizes,\n",
        "        mode=\"auto\",           # 'linear' | 'circular' | 'auto'\n",
        "        angle_mask=None        # or a boolean array of length len(epoch_weights[0])\n",
        "    )\n",
        "\n",
        "    print(f\"[AUTO] mode={diag['used_mode']} | R_mean={diag['R_mean']:.3f} | \"\n",
        "          f\"straddle={diag['straddle_frac']:.3f} | sse_gap={diag['sse_geo_gap']:.4f}\")\n",
        "\n",
        "\n",
        "        # Update the global model weights\n",
        "    print(\"Global model updated\")\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    # --- remove these lines ---\n",
        "# new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch], num_features)\n",
        "# for index, client in enumerate(clients):\n",
        "#     client[\"primary_model\"] = new_model_with_global_weights\n",
        "# global_acc = compute_global_accuracy(new_model_with_global_weights, clients)\n",
        "# --------------------------------\n",
        "\n",
        "    # --- insert this instead ---\n",
        "    avg_w = global_model_weights[epoch]\n",
        "    # Use any client model that was trained this epoch as a *fitted prototype*:\n",
        "    prototype = clients[0].primary_model # Use dot notation\n",
        "    global_acc = compute_global_accuracy_from_weights(prototype, avg_w, clients)\n",
        "    global_model_accuracy.append(global_acc)\n",
        "\n",
        "    # set starting point for the NEXT epoch’s training\n",
        "    for c in clients:\n",
        "        c.next_init = avg_w.copy() # Use dot notation\n",
        "        c.primary_model.initial_point = np.asarray(avg_w) # Use dot notation\n",
        "\n",
        "\n",
        "    # # Calculate global accuracy using the test data\n",
        "    # test_sequences = clients[0][\"test_data\"][\"sequence\"]  # Access test_sequences\n",
        "    # test_labels = clients[0][\"test_data\"][\"label\"]  # Access test_labels\n",
        "    # global_accuracy = getAccuracy(global_model_weights[epoch], num_features, test_sequences, test_labels)\n",
        "    # global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    # Save the clients' train/test accuracies for this epoch\n",
        "    clients_train_accuracies.append(epoch_train_accuracies)\n",
        "    clients_test_accuracies.append(epoch_test_accuracies)\n",
        "\n",
        "    # compute global accuracy on the combined test set\n",
        "    # global_acc = compute_global_accuracy(new_model_with_global_weights, clients) # This line was removed in the original cell\n",
        "    # global_model_accuracy.append(global_acc) # This line was removed in the original cell\n",
        "    # Example: append to a separate file\n",
        "    with open(\"angle_diag.csv\", \"a\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        if epoch == 0:\n",
        "            w.writerow([\"epoch\",\"used_mode\",\"R_mean\",\"straddle_frac\",\"sse_geo_gap\"])\n",
        "        w.writerow([epoch, diag[\"used_mode\"], diag[\"R_mean\"], diag[\"straddle_frac\"], diag[\"sse_geo_gap\"]])\n",
        "\n",
        "    # APPEND one row to Drive for this epoch\n",
        "    append_metrics_row(\n",
        "        CSV_PATH,\n",
        "        epoch,\n",
        "        global_acc,\n",
        "        epoch_train_accuracies,\n",
        "        epoch_test_accuracies\n",
        "    )\n",
        "\n",
        "    # print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    print(f\"[Epoch {epoch}] global_acc={global_acc:.4f} \"\n",
        "          f\"| train={epoch_train_accuracies} | test={epoch_test_accuracies}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fxtq4-9VQsF"
      },
      "source": [
        "Visualizing Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9T-8JBzwMo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "filename = 'accuracies.csv'\n",
        "data = pd.read_csv(filename)\n",
        "\n",
        "# Extract the relevant columns for plotting\n",
        "epochs = data['Epoch']\n",
        "global_accuracy = data['Global Accuracy']\n",
        "client_train_accuracies = data.filter(like='Train Accuracy').values\n",
        "client_test_accuracies = data.filter(like='Test Accuracy').values\n",
        "\n",
        "# Plot Global Accuracy over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs, global_accuracy, label='Global Accuracy', color='blue', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Global Accuracy')\n",
        "plt.title('Global Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Train Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_train_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_train_accuracies[:, i], label=f'Client {i} Train Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Train Accuracy')\n",
        "plt.title('Train Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot Test Accuracies for all clients over Epochs\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i in range(client_test_accuracies.shape[1]):\n",
        "    plt.plot(epochs, client_test_accuracies[:, i], label=f'Client {i} Test Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.title('Test Accuracies for All Clients Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a_q7UqBTcju"
      },
      "source": [
        "new ways to average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dd3Im7PfTkl9"
      },
      "outputs": [],
      "source": [
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # First time training: no existing model\n",
        "            train_score_q, test_score_q, model = train(data=client.data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            # Continue training with the existing model\n",
        "            train_score_q, test_score_q, model = train(data=client.data[epoch], model=client.primary_model)\n",
        "\n",
        "        # Save model and scores\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        # Extract and collect model weights\n",
        "        print(f\"Train Score: {train_score_q}\")\n",
        "        print(f\"Test Score: {test_score_q}\")\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "        # Assuming model.weights returns a NumPy array or list of weights\n",
        "        epoch_weights.append(model.weights)\n",
        "\n",
        "    # Average the weights across all clients\n",
        "    average_weights = sum(epoch_weights) / len(epoch_weights)\n",
        "\n",
        "    # Create a new model with the averaged global weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "    new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch])\n",
        "\n",
        "    # Update each client's primary model with the global averaged weights\n",
        "    for index, client in enumerate(clients):\n",
        "        client.primary_model = new_model_with_global_weights\n",
        "\n",
        "    # Optionally calculate global accuracy (if applicable in your case)\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])  # Assuming getAccuracy() works with global weights\n",
        "    global_model_accuracy.append(global_accuracy)\n",
        "\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skaTQsAsTbbr"
      },
      "outputs": [],
      "source": [
        "# Function to extract numerical values of parameters\n",
        "def extract_param_values(model):\n",
        "    param_values = []\n",
        "    # Loop through each parameter in the circuit and get its bound value\n",
        "    for param in model.neural_network.circuit.parameters:\n",
        "        # Extract the numerical value (assuming they are already bound with values)\n",
        "        bound_value = model.neural_network.circuit._parameters[param]\n",
        "        param_values.append(bound_value)\n",
        "    return np.array(param_values)\n",
        "\n",
        "# Function to set numerical values of parameters back into the circuit\n",
        "def set_param_values(model, param_values):\n",
        "    # Assign the averaged parameter values back to the circuit\n",
        "    parameter_dict = {param: value for param, value in zip(model.neural_network.circuit.parameters, param_values)}\n",
        "    model.neural_network.circuit.assign_parameters(parameter_dict)\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch], model=client.primary_model)\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"  \")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        # Collect model weights (extract numerical parameter values)\n",
        "        param_values = extract_param_values(client.primary_model)\n",
        "        epoch_weights.append(param_values)\n",
        "\n",
        "    # Average the numerical values of the parameters across clients\n",
        "    average_weights = np.mean(epoch_weights, axis=0)\n",
        "\n",
        "    # Manually update each client's model parameters with the averaged weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    for client in clients:\n",
        "        # Manually set the global averaged weights to the model's parameters\n",
        "        set_param_values(client.primary_model, global_model_weights[epoch])\n",
        "\n",
        "    # Calculate global accuracy\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "\n",
        "    # Print global accuracy for the epoch\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MK8swGngN3RP"
      },
      "source": [
        "33333333333333333333333333333333333333333333"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUX7LWLUIvFu"
      },
      "outputs": [],
      "source": [
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "# Function to train the QNN model for one client\n",
        "def train_qnn_model(client_data,client_test_data, model=None):\n",
        "    #num_features = client_data[0][\"sequence\"].shape[0]  # Get the feature dimension\n",
        "    # Debug: Print the client data structure\n",
        "    print(\"Client Test Data Structure:\", client_test_data)\n",
        "    if model is None:\n",
        "        # Create a new QNN model if one doesn't exist\n",
        "        model = create_qnn_model(client_data)\n",
        "\n",
        "    # Extract sequences and labels for training\n",
        "    train_sequences = [data_point[\"sequence\"] for data_point in client_data]\n",
        "    train_labels = [data_point[\"label\"] for data_point in client_data]\n",
        "\n",
        "    # Extract sequences and labels for testing\n",
        "    # Handle test data\n",
        "    if isinstance(client_test_data, dict):\n",
        "        # Single data point (dictionary format)\n",
        "        test_sequences = np.array([client_test_data[\"sequence\"]])\n",
        "        test_labels = np.array([client_test_data[\"label\"]])\n",
        "    else:\n",
        "        # List of dictionaries (multiple data points)\n",
        "        test_sequences = [data_point[\"sequence\"] for data_point in client_test_data]\n",
        "        test_labels = [data_point[\"label\"] for data_point in client_test_data]\n",
        "        test_sequences = np.array(test_sequences)\n",
        "        test_labels = np.array(test_labels)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    train_sequences = np.array(train_sequences)\n",
        "    train_labels = np.array(train_labels)\n",
        "\n",
        "\n",
        "    print(\"Training started...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train the QNN model\n",
        "    model.fit(train_sequences, train_labels)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f\"Training completed in {elapsed_time} seconds.\")\n",
        "\n",
        "    # Evaluate the model on training and test data\n",
        "    train_score_q = model.score(train_sequences, train_labels)\n",
        "    test_score_q = model.score(test_sequences, test_labels)\n",
        "\n",
        "    return model, train_score_q, test_score_q, elapsed_time\n",
        "\n",
        "# Federated learning loop\n",
        "for epoch in range(num_epochs):\n",
        "    global_model_weights[epoch] = []\n",
        "    epoch_weights = []\n",
        "    print(f\"Epoch: {epoch}\")\n",
        "\n",
        "    # Train each client\n",
        "    for index, client in enumerate(clients):\n",
        "        print(f\"Training Client {index}\")\n",
        "\n",
        "        if client.primary_model is None:\n",
        "            # Pass both training and test data to the training function\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch])\n",
        "            client.primary_model = model\n",
        "        else:\n",
        "            model, train_score_q, test_score_q, train_time = train_qnn_model(client.data[epoch], client.test_data[epoch], model=client.primary_model)\n",
        "\n",
        "        client.models.append(model)\n",
        "        client.train_scores.append(train_score_q)\n",
        "        client.test_scores.append(test_score_q)\n",
        "\n",
        "        print(f\"Client {index} Train Score: {train_score_q}\")\n",
        "        print(f\"Client {index} Test Score: {test_score_q}\")\n",
        "        print(\"  \")\n",
        "        print(\"----------------------------------------------------------\")\n",
        "\n",
        "        for model in client.models:\n",
        "        # Extract numerical values of parameters (as a NumPy array)\n",
        "            param_values = [p.value for p in model.neural_network.circuit.parameters] # Extract the values\n",
        "            epoch_weights.append(param_values)\n",
        "\n",
        "    # Average the numerical values of the parameters across clients\n",
        "    average_weights = np.mean(epoch_weights, axis=0)\n",
        "\n",
        "    # Manually update each client's model parameters with the averaged weights\n",
        "    global_model_weights[epoch] = average_weights\n",
        "\n",
        "    for client in clients:\n",
        "        # Manually set the global averaged weights to the model's parameters\n",
        "        for i, param in enumerate(client.primary_model.neural_network.circuit.parameters):\n",
        "            client.primary_model.neural_network.circuit._parameters[param] = average_weights[i] # Set the value directly\n",
        "\n",
        "\n",
        "    # Calculate global accuracy\n",
        "    global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "\n",
        "    # Print global accuracy for the epoch\n",
        "    print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy:.2f}\")\n",
        "    print(\"----------------------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqzOZRiKN2FE"
      },
      "outputs": [],
      "source": [
        "\n",
        "import time\n",
        "\n",
        "itr = 0\n",
        "def training_callback(weights, obj_func_eval):\n",
        "        global itr\n",
        "        itr += 1\n",
        "        print(f\"{itr}\", end=' | ')\n",
        "def train(data, model = None):\n",
        "  if model is None:\n",
        "    num_features = len(data[0][\"sequence\"])\n",
        "    feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "    ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "    optimizer = COBYLA(maxiter=max_train_iterations)\n",
        "    vqc_model = VQC(\n",
        "        feature_map=feature_map,\n",
        "        ansatz=ansatz,\n",
        "        optimizer=optimizer,\n",
        "        callback=partial(training_callback),\n",
        "        sampler=BackendSampler(backend=backend),\n",
        "        warm_start=True\n",
        "    )\n",
        "    model = vqc_model\n",
        "\n",
        "  train_sequences = [data_point[\"sequence\"] for data_point in data]\n",
        "  train_labels = [data_point[\"label\"] for data_point in data]\n",
        "\n",
        "  # Convert the lists to NumPy arrays\n",
        "  train_sequences = np.array(train_sequences)\n",
        "  train_labels = np.array(train_labels)\n",
        "\n",
        "  # Print the shapes\n",
        "  print(\"Train Sequences Shape:\", train_sequences.shape)\n",
        "  print(\"Train Labels Shape:\", train_labels.shape)\n",
        "\n",
        "  print(\"Training Started\")\n",
        "  start_time = time.time()\n",
        "  model.fit(train_sequences, train_labels)\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nTraining complete. Time taken: {elapsed_time} seconds.\")\n",
        "\n",
        "  print(f\"SCORING MODEL\")\n",
        "  train_score_q = model.score(train_sequences, train_labels)\n",
        "  test_score_q = model.score(test_sequences[:200], test_labels[:200])\n",
        "  return train_score_q, test_score_q, model\n",
        "\n",
        "def getAccuracy(weights):\n",
        "        num_features = len(test_sequences[0])\n",
        "        feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "        ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "        ansatz = ansatz.bind_parameters(weights)\n",
        "        optimizer = COBYLA(maxiter=0)\n",
        "        vqc = VQC(\n",
        "            feature_map=feature_map,\n",
        "            ansatz=ansatz,\n",
        "            optimizer=optimizer,\n",
        "            sampler=BackendSampler(backend=backend)\n",
        "        )\n",
        "        vqc.fit(test_sequences[:25], test_labels[:25])\n",
        "        return vqc.score(test_sequences[:200], test_labels[:200])\n",
        "\n",
        "def create_model_with_weights(weights):\n",
        "  num_features = len(test_sequences[0])\n",
        "  feature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\n",
        "  ansatz = RealAmplitudes(num_qubits=num_features, reps=3)\n",
        "  optimizer = COBYLA(maxiter=max_train_iterations)\n",
        "  vqc = VQC(\n",
        "      feature_map=feature_map,\n",
        "      ansatz=ansatz,\n",
        "      optimizer=optimizer,\n",
        "      sampler=BackendSampler(backend=backend),\n",
        "      warm_start = True,\n",
        "      initial_point  = weights,\n",
        "      callback=partial(training_callback)\n",
        "  )\n",
        "  return vqc\n",
        "\n",
        "\n",
        "global_model_weights = {}\n",
        "global_model_accuracy = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  global_model_weights[epoch] = []\n",
        "  epoch_weights = []\n",
        "  print(f\"epoch: {epoch}\")\n",
        "  for index, client in enumerate(clients):\n",
        "    print(f\"Index: {index}, Client: {client}\")\n",
        "\n",
        "    if client.primary_model is None:\n",
        "      train_score_q, test_score_q, model = train(data = client.data[epoch])\n",
        "      client.models.append(model)\n",
        "      client.test_scores.append(test_score_q)\n",
        "      client.train_scores.append(train_score_q)\n",
        "      # Print the values\n",
        "      print(\"Train Score:\", train_score_q)\n",
        "      print(\"Test Score:\", test_score_q)\n",
        "      print(\"\\n\\n\")\n",
        "      epoch_weights.append(model.weights)\n",
        "\n",
        "    else:\n",
        "      train_score_q, test_score_q, model = train(data = client.data[epoch], model = client.primary_model)\n",
        "      client.models.append(model)\n",
        "      client.test_scores.append(test_score_q)\n",
        "      client.train_scores.append(train_score_q)\n",
        "      print(\"Train Score:\", train_score_q)\n",
        "      print(\"Test Score:\", test_score_q)\n",
        "      print(\"\\n\\n\")\n",
        "      epoch_weights.append(model.weights)\n",
        "\n",
        "\n",
        "if(epoch != 0):\n",
        "    epoch_weights.append(global_model_weights[epoch-1])\n",
        "average_weights = sum(epoch_weights) / len(epoch_weights)\n",
        "\n",
        "global_model_weights[epoch] = average_weights\n",
        "new_model_with_global_weights = create_model_with_weights(global_model_weights[epoch])\n",
        "for index, client in enumerate(clients):\n",
        "  client.primary_model = new_model_with_global_weights\n",
        "\n",
        "global_accuracy = getAccuracy(global_model_weights[epoch])\n",
        "print(f\"Global Model Accuracy In Epoch {epoch}: {global_accuracy}\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "global_model_accuracy.append(global_accuracy)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3iRt+0vdfCWfYKY54RNfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}